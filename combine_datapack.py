
# Combines The images, depth data, camera poses, and object masks back into one npz file


import argparse
import os
import pytorch3d
import pytorch3d.transforms
import numpy as np
import torch
from PIL import Image


# Unpacks an npz file containing the data generated by record_kinect.py
# Saves the images to a folder so they can be processed by colmap

def unpack(npz_filename):
    data = np.load(npz_filename, allow_pickle=True)
    rgb_data = data["rgb_data"]#.astype(np.float32)
    depth_data = data["depth_data"]#.astype(np.float32)

    # depth_data = data["depth_data"].astype(np.float32)
    # print("max", np.max(depth_data))
    # print("min", np.min(depth_data))

    return rgb_data, depth_data


def read_masks(masks_path):
    # Masks are individual images in folder
    # Mask filenames follow the pattern: "mask i.png"
    # Map filename to mask image
    masks = {}
    mask_filenames = os.listdir(masks_path)
    for mask_filename in mask_filenames:
        mask = Image.open(os.path.join(masks_path, mask_filename))
        mask = np.array(mask)
        masks[mask_filename] = mask

    return masks


# Takes camera poses from an images.txt file and converts them to pytorch3d format

def read_images_txt(txt_filename):
    # The first 4 lines are just comments, so skip them
    
    f = open(txt_filename, 'r')
    for i in range(4):
        f.readline()
    
    # Two lines per image
    # Data format is:
    # IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME
    # POINTS2D[] as (X, Y, POINT3D_ID)
    cameras = {}
    while True:
        line_data = f.readline().split(" ")
        if len(line_data) < 3:
            break
        print("line_data", line_data)

        quaternion = np.array(line_data[1:5])
        quaternion = quaternion.astype(np.float32)
        quaternion = torch.tensor(quaternion)
        # print("Quaternion len:", len(quaternion))
        R = pytorch3d.transforms.quaternion_to_matrix(quaternion)
        R = R.unsqueeze(0)
        T = np.array(line_data[5:8]).astype(np.float32)
        T = torch.tensor(T).unsqueeze(0)

        cam_name = line_data[9].strip("\n")
        print("cam:", cam_name)
        # print("R", R)
        # print("T", T)

        cam = {"filename": cam_name,
               "R": R,
               "T": T}

        cameras[cam_name] = cam


        throwaway = f.readline()
    return cameras


def pack(rgb_data, depth_data, camera_pose_data, masks, output_name):

    # camera_pose_data = data["camera_pose_data"]
    mask_data = []
    cam_poses = []
    
    for i, image in enumerate(rgb_data):
        mask_name = f"{i}.png"
        cam_name = f"{i}.png"
        mask_data.append(masks[mask_name])
        cam_poses.append(camera_pose_data[cam_name])

        print("i", i)
        print(image.shape)
        print("max", np.max(image))
        print("min", np.min(image))
        print(f"shape of image[:, :, 0:3]: {image[:,:,0:3].shape}")
        print("image.dtype", image.dtype)
        print("depth.dtype", depth_data[i].dtype)
        # Save image as png
        #img = Image.fromarray(image[:,:,0:3][:,:,::-1], "RGB")
        #img.save(f"images/{i}.png")
    
    #with open(os.path.join(data_dir, out_name + ".npz"), 'wb') as f:
    print("Saving output npz")
    with open(output_name, 'wb') as f:
        np.savez(f, rgb_data=rgb_data, depth_data=depth_data, camera_pose_data=cam_poses, mask_data=mask_data)
    print("Saved " + output_name)



if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("--imagestxt_path", type=str, default=None)
    parser.add_argument("--kinect_npz", type=str, default=None)
    parser.add_argument("--masks_dir", type=str, default=None)
    parser.add_argument("--output_name", type=str, default="kinect_data.npz")
    args = parser.parse_args()

    # args.imagestxt_path = "exported/images.txt"
    # args.kinect_npz = "kinect_data1682542012.6715932.npz"
    # args.masks_dir = "masks"
    cameras = read_images_txt(args.imagestxt_path)
    rgb_data, depth_data = unpack(args.kinect_npz)
    masks = read_masks(args.masks_dir)

    pack(rgb_data, depth_data, cameras, masks, args.output_name)
